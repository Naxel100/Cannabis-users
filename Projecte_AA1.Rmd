---
title: "Drug consumption"
author: "Alex Ferrando de las Morenas, Carlos Hurtado Comín, Maria Ribot Vilà"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

### Importació llibreries necessàries per la pràctica

```{r}
library(naivebayes)   # Necessària per fer Naive Bayes
library(rockchalk)    # Necessària per la funció combineLevels
library(MASS)         # Utils per funcions estadístiques
library(ca)           # Per fer l'anàlisi de correspondències
library(nnet)         # Per a implementar la neural network
library(caret)        # Per al trainControl
library(randomForest) # Random forest
library(ggplot2)      # Per fer plots
```

#### Lectura de la base de dades.

```{r}
dd = read.csv("drug_consumption.data", header = F)
colnames(dd) = c("ID","Age","Gender","Education","Country","Ethnicity","Nscore",
                  "Escore","Oscore","Ascore" ,"Cscore", "Impulsive", "SS", "Alcohol",
                  "Amphet","Amyl","Benzos","Caff","Cannabis","Choc","Coke","Crack",
                  "Ecstasy","Heroin","Ketamine","Legalh","LSD","Meth","Mushrooms",
                  "Nicotine","Semer" ,"VSA")
dd = dd[,-6]
```

### Binarització de les variable resposta

```{r}
dd[, "Cannabis"] = combineLevels(dd[, "Cannabis"], levs = c("CL0", "CL1", "CL2"), 
                                 newLabel = "NON-USER")
dd[, "Cannabis"] = combineLevels(dd[, "Cannabis"], levs = c("CL3", "CL4", "CL5", "CL6"), 
                                 newLabel = "USER")
```

Copiem la base de dades en *dd2* per poder fer un estudi previ coherent i sense la pèrdua d'interpretabilitat que genera el tractament previ que han tingut les dades i la consegüent transformació de factors a valors reals.

```{r}
dd2 = dd

dd2$Age = as.factor(dd2$Age)
levels(dd2$Age) = c("18-24", "25-34", "35-44", "45-54", "55-64","65+")

dd2$Gender = as.factor(dd2$Gender)
levels(dd2$Gender) = c("Male", "Female")

dd2$Education = as.factor(dd2$Education)
levels(dd2$Education) = c("< 16", "16", "17", "18", "> 18", 
                          "Professional Certificate", "University", "Master", 
                          "Doctorate")

dd2$Country = as.factor(dd2$Country)
levels(dd2$Country) = c("USA", "New Zealand", "Other", "Australia", "Ireland", "Canada",
                        "UK")

dd2$Nscore = as.factor(dd2$Nscore)
levels(dd2$Nscore) = 12:60
dd2$Nscore = as.integer(dd2$Nscore)

dd2$Escore = as.factor(dd2$Escore)
levels(dd2$Escore) = setdiff(16:59, 17)
dd2$Escore = as.integer(dd2$Escore)

dd2$Oscore = as.factor(dd2$Oscore)
levels(dd2$Oscore) = setdiff(24:60, c(25, 27))
dd2$Oscore = as.integer(dd2$Oscore)

dd2$Ascore = as.factor(dd2$Ascore)
levels(dd2$Ascore) = setdiff(12:60, c(13, 14, 15, 17, 19, 20, 21, 22))
dd2$Ascore = as.integer(dd2$Ascore)

dd2$Cscore = as.factor(dd2$Cscore)
levels(dd2$Cscore) = setdiff(17:59, c(18, 58))
dd2$Cscore = as.integer(dd2$Cscore)

dd2$Impulsive = as.factor(dd2$Impulsive)
levels(dd2$Impulsive) = 1:10
dd2$Impulsive = as.integer(dd2$Impulsive)

dd2$SS = as.factor(dd2$SS)
levels(dd2$SS) = 1:11
dd2$SS = as.integer(dd2$SS)
```

# 1. Preprocessament de les dades

## 1.1 Estudi de les dades

```{r}
summary(dd2[, c(2:13, 29, 18)])
```

## 1.2 Barplots i graficació de taules de contingència

```{r}
par(mfrow = c(1, 2), mex = 0.4)
for(i in c(2:5, 13, 29)) {
   tab =  table(dd2$Cannabis, dd2[,i])
   barplot(tab, beside = TRUE, legend = levels(dd$Cannabis), main = colnames(dd2)[i])
   plot(tab, main = "")
}

for(i in 6:12) {
   tab =  table(dd2$Cannabis, dd2[,i])
   barplot(tab, beside = TRUE, legend = levels(dd$Cannabis), main = colnames(dd2)[i])
}
```


## 1.3 Histogrames scores

```{r}
par(mfrow = c(1,2))
v = which(dd[, "Cannabis"] == "USER")
for (i in 6:10){
   hist(dd[-v, i], main = paste(colnames(dd)[i], "NON-USER"), col = "grey30", 
        xlab = "Scores normalitzats")
   hist(dd[v, i], main = paste(colnames(dd)[i], "USER"), col = "grey90", 
        xlab = "Scores normalitzats")
}
```

## 1.4 Anàlisi de correspondències

```{r}
ca = mjca(dd2[,c(2:4, 18)], lambda = "Burt")
plot(ca, main = "Edat, educació i gènere")
ca = mjca(dd2[,c(13, 29, 18)], lambda = "Burt")
plot(ca, main = "Alcohol i nicotina")
```

## 1.5 Test de Wilcox per les variables de personalitat

### 1.5.1 Normalitat variables de personalitat

```{r}
par(mfrow = c(2, 2), mex = 0.7)

for (i in 6:12) {
   qqnorm(dd2[, i])
   qqline(dd2[, i])
}
```

```{r}
for (i in 6:12){
   print(wilcox.test(dd[, i] ~ dd$Cannabis))
}
```


## 1.6 Estudi normalitat per a l'ús de QDA i LDA

Normalitat variable per variable en la base de dades *dd* que és la base amb les transformacions a valors reals que serà la que s'utilitzarà per a la implementació de QDA i LDA.

```{r}
par(mfrow = c(2, 2), mex = 0.7)

for (i in 6:12) {
   qqnorm(dd[, i])
   qqline(dd[, i])
}
```

Normalitat multivariada de tot el conjunt de variables explicatives que conformen les dades d'entrenament.

```{r}
db = as.matrix(dd[,2:12])
S = cov(db) # Matriu de covariàncies
d = matrix(0, 1, nrow(db))
m = apply(db,2,mean)
# Mahanalobis
for (i in 1:nrow(db)){
   d[i] = t(db[i,] - m) %*% solve(S) %*% (db[i,] - m)
}
# Ordenem pel rank
d = sort(d);
# Correcció de ranks
aux = seq(1, nrow(db))
aux = (aux - 0.5) / nrow(db)
plot(qchisq(aux, ncol(db)), d,xlab = "Index", ylab = "chisq", 
     main = "Test normal multivariada")
abline(0, 1)
```

### 1.6.1 Plot LDA

```{r}
l = lda(dd[, c(2:12)], grouping = dd[, "Cannabis"])
plot(l, col = "grey")
```

# 2. Entrenament

## 2.1 Separació les dades en training y test 

Traiem la variable *Escore* que hem detectat que és no significativa.

```{r}
dd = dd[,-7]
dd2 = dd2[,-7]
```


```{r}
n = nrow(dd)

set.seed(20)
samples = sample(n, round(0.75*n))  # Reservem el 25% de les dades per test
train = dd2[samples, c(2:12, 28, 17)]  # Dades de train amb categories 
train.real = dd[samples, c(2:12, 28, 17)]  # Dades de training amb reals
test = dd2[-samples, c(2:12, 28, 17)]  # Dades de test amb categories
test.real = dd[-samples, c(2:12, 28, 17)]  # Dades de test amb reals

ntr = nrow(train)
nte = nrow(test)
```


## Funcions auxiliars 

## 2.2 Error QDA

Donat un conjunt de dades d'entrenament i de validació i les seves respectives respostes retorna l'error sobre el conjunt de validació havent creat un model amb QDA (suposició de matrius de covariàncies diferents) amb les dades d'entrenament.

```{r}
error_qda = function (Xl, yl, Xv, yv, flag) {
   out = qda(yl ~ ., data = Xl)
   pred = predict(out, newdata = Xv)$class
   prediction = table(Truth = yv, Pred = pred)
   if (flag) print(prediction)
   err = 1 - sum(diag(prediction))/length(yv)
}
```


## 2.3 Error LDA

Donat un conjunt de dades d'entrenament i de validació i les seves respectives respostes retorna l'error sobre el conjunt de validació havent creat un model amb LDA (suposició de matrius de covariàncies iguals) amb les dades d'entrenament.

```{r}
error_lda = function (Xl, yl, Xv, yv, flag) {
   out = lda(yl ~ ., data = Xl)
   pred = predict(out, newdata = Xv)$class
   prediction = table(Truth = yv, Pred = pred)
   if (flag) print(prediction)
   err = 1 - sum(diag(prediction))/length(yv)
}
```

## 2.4 Error GLM

Aquesta funció genera un model lineal generaltizat binomial amb link inidicat al paràmetre d'entrada *linkage* amb les dades d'entrenament i retorna l'error comés sobre el conjunt de dades de validació. De nou incloem un *flag* que ens indica si volem fer el print de taula de confusió o no.

```{r}
error_glm = function (Xl, yl, Xv, yv, linkage, flag) {
   # Generació del model amb les dades de learn
   mod = glm(yl ~ ., family = binomial(link = linkage), data = as.data.frame(Xl))

   # Predicció sobre les dades de validació
   PI = predict(mod, newdata = as.data.frame(Xv), type = "response")
   PI = as.factor(round(PI))
   levels(PI) = c("USER", "NON-USER")
   prediction = table(Truth = yv, Pred = PI)
   if (flag) print(prediction)
   err = 1 - sum(diag(prediction))/length(yv)
}
```

## 2.5 Error Naive-Bayes

Retorna l'error de predicció sobre el conjunt de dades de validació entrenant un model Naive-Bayes per classificar amb les dades d'entrenament passades com a entrada.

```{r}
error_naivebayes = function (Xl, yl, Xv, yv, flag) {
   # Generació del model amb les dades de learn
   mod = naive_bayes(Xl, yl, laplace = 0.1)
   
   # Predicció sobre les dades de validació
   PI = predict(mod, newdata = Xv, type = "class")
   prediction = table(Truth = yv, Pred = PI)
   if (flag) print(prediction)
   err = 1 - sum(diag(prediction))/length(yv)
}
```

## 2.6 Multilayer perceptron

Donat un conjunt de dades de train i de test retorna l'error sobre el conjunt de test en implementar un *Multilayer perceptron* amb una única capa oculta amb el nombre de neurones i *decay* indicats a l'entrada.

```{r}
error_nnet = function (Xl, yl, Xv, yv, size, decay, flag) {
   out = nnet(yl ~ ., data = Xl, size = size, decay = decay, maxit = 10000, trace = F, MaxNWts = 10000)
   pred = predict(out, newdata = Xv, type = "class")
   prediction = table(Truth = yv, Pred = pred)
   if (flag) print(prediction)
   err = 1 - sum(diag(prediction))/length(yv)
}
```

### 2.6.1 Elecció hiperparàmetres nnet

Fem un plot de l'error de training i de validació en fer un 10-times 10-fold cross validation modificant el número de neurones de la capa oculta de la xarxa.

```{r}
sizes = seq(1, 16, 1)

tr.error = rep(0, 16)
te.error = rep(0, 16)
cont = 1

for (k in sizes) {
   err = c("training" = 0, "test" = 0)
   for (i in 1:10) {
      samples = sample(ntr)  # Barrejem aleatòriament les dades de training
      for (j in 1:10) {
         start = round((j - 1)*ntr/10 + 1) # Índex inici
         end = round(j * ntr/10)  # Índex final
         
         # Separem en variables explicatives i resposta / learn i validation
         Xl = train[samples[-(start:end)], -13]
         yl = train[samples[-(start:end)], 13]
         Xv = train[samples[start:end], -13]
         yv = train[samples[start:end], 13]
         
         err["test"] = err["test"] + error_nnet(Xl, yl, Xv, yv, k, 0, F)
         err["training"] = err["training"] + error_nnet(Xl, yl, Xl, yl, k, 0, F)
      }
   }
   tr.error[cont] = err["training"]
   te.error[cont] = err["test"]
   cont = cont + 1
}
ggplot(as.data.frame(tr.error), aes(sizes)) + 
  geom_line(aes(y = tr.error, colour = "tr.error")) + 
  geom_line(aes(y = te.error, colour = "te.error")) +
  labs(x = "number of neurons", y = "error")
```


```{r}
best.size = 10
```

Agafem 10 neurones ja que observem que a partir d'aquest punt sobreparametritzem. Fixem ara el nombre de neurones i busquem el decay òptim de nou amb un 10-times 10-fold cross validation.

```{r}
set.seed(41)
decays = seq(1.5, 2.5, by = 0.1)
trc = trainControl(method = "repeatedcv", number = 10, repeats = 10)

model.10x10CV = train(Cannabis ~ ., data = train, 
                        method = 'nnet', maxit = 1000, trace = FALSE,
                      tuneGrid = expand.grid(.size = best.size, .decay = decays), trControl = trc)
(decay = model.10x10CV$bestTune$decay)
```

```{r}
model.10x10CV
```


### 2.7 Random forest

Aquest funció retorna l'error en ajustar un model amb un Random Forest de mida k.

```{r}
error_randomforest = function (Xl, yl, Xv, yv, k, flag) {
   rf = randomForest (yl ~ ., data = as.data.frame(Xl), ntree = k, proximity = FALSE)
   pred = predict(rf, newdata = Xv, type = "class") 
   prediction = table(Truth = yv, Pred = pred)
   if (flag) print(prediction)
   err = 1 - sum(diag(prediction))/length(yv)
}
```

Fem un plot de l'error de training i de validació en fer 10-times 10-fold cross validation en canviar el nombre d'arbres d'un Random Forest.

```{r}
set.seed(12)
ntrees = seq(1, 101, 2)
min_err = 100

tr.error = rep(0, 51)
te.error = rep(0, 51)
cont = 1

for (k in ntrees) {
   err = c("training" = 0, "test" = 0)
   for (i in 1:10) {
      samples = sample(ntr)  # Barrejem aleatòriament les dades de training
      for (j in 1:10) {
         start = round((j - 1)*ntr/10 + 1)  # Índex inici
         end = round(j * ntr/10)  # Índex final
         
         # Separem en variables explicatives i resposta / learn i validation
         Xl = train[samples[-(start:end)], -13]
         yl = train[samples[-(start:end)], 13]
         Xv = train[samples[start:end], -13]
         yv = train[samples[start:end], 13]
         
         err["test"] = err["test"] + error_randomforest(Xl, yl, Xv, yv, k, F)
         err["training"] = err["training"] + error_randomforest(Xl, yl, Xl, yl, k, F)
      }
   }
   tr.error[cont] = err["training"]
   te.error[cont] = err["test"]
   cont = cont + 1
}

ggplot(as.data.frame(tr.error), aes(ntrees)) + 
  geom_line(aes(y = tr.error, colour = "tr.error")) + 
  geom_line(aes(y = te.error, colour = "te.error")) +
  labs(x = "number of trees", y = "error")
```

```{r}
best.ntree = 50
```


### 2.8 Cross-validation

Fem un 10 times 10-fold cross validation per avaluar quin dels models proposats és el millor. En aquest cas hem usat *QDA*, *LDA*, *GLM link logit*, *GLM link probit*, *GLM link loglog*, *Naive Bayes*, *MLP* i *Random Forest*.

```{r, warning=F}
set.seed(5)
error = c("QDA" = 0, "LDA" = 0, "GLM-logit" = 0, "GLM-probit" = 0, "GLM-loglog" = 0, 
          "Naive-Bayes" = 0, "Nnet" = 0, "Random Forest"  = 0)

for (i in 1:10) {
   samples = sample(ntr)  # Barrejem aleatòriament les dades de training
   for (j in 1:10) {
      start = round((j - 1)*ntr/10 + 1)  # Índex d'inici del j-èssim-fold validation test
      end = round(j * ntr/10)  # Índex final
      
      # Separem en variables explicatives i resposta / learn i validation
      # 1. Training i validation amb la base de dades amb categòriques
      Xl = train[samples[-(start:end)], -13]
      yl = train[samples[-(start:end)], 13]
      Xv = train[samples[start:end], -13]
      yv = train[samples[start:end], 13]
      
      # 2. Raining i validation amb la base de dades amb reals
      Xl.r = train.real[samples[-(start:end)], -(11:13)]
      yl.r = train.real[samples[-(start:end)], 13]
      Xv.r = train.real[samples[start:end], -(11:13)]
      yv.r = train.real[samples[start:end], 13]
      
      # Actualització errors
      error["QDA"] = error["QDA"] + error_qda(Xl.r, yl.r, Xv.r, yv.r, F)
      error["LDA"] = error["LDA"] + error_lda(Xl.r, yl.r, Xv.r, yv.r, F)
      error["GLM-logit"] = error["GLM-logit"] + error_glm(Xl, yl, Xv, yv, "logit", F)
      error["GLM-probit"] = error["GLM-probit"] + error_glm(Xl, yl, Xv, yv, "probit", F)
      error["GLM-loglog"] = error["GLM-loglog"] + error_glm(Xl, yl, Xv, yv, "cloglog", F)
      error["Naive-Bayes"] = error["Naive-Bayes"] + error_naivebayes(Xl, yl, Xv, yv, F)
      error["Nnet"] = error["Nnet"] + error_nnet(Xl, yl, Xv, yv, best.size, decay, F)
      error["Random Forest"] = error["Random Forest"] + error_randomforest(Xl, yl, Xv, yv,
                                                                           best.ntree, F)
   }
}
error
```


### 2.9 Error sobre les dades de test

```{r}
set.seed(0415)
droga = "Cannabis"

print("GLM")
a = cbind("te. error", error_glm(train[, -13], train[, droga], test[, -13], 
                                 test[, droga], "logit", T))
a = rbind(a, cbind("tr. error", error_glm(train[, -13], train[, droga], train[, -13], 
                                          train[, droga], "logit", T)))
a

print("Naive Bayes")
a = cbind("te. error", error_naivebayes(train[, -13], train[, droga], test[, -13], 
                                        test[, droga], T))
a = rbind(cbind(a, error_naivebayes(train[, -13], train[, droga], train[, -13], 
                                    train[, droga], T)))
a

print("nnet")
a = cbind("te. error", error_nnet(train[, -13], train[, droga], test[, -13], 
                                  test[, droga], best.size, decay, T))
a = rbind(a, cbind("tr. error", error_nnet(train[, -13], train[, droga], train[, -13], 
                                           train[, droga], best.size, decay, T)))
a

print("Random Forest")
a = cbind("te. error", error_randomforest(train[, -13], train[, droga], test[, -13], 
                                          test[, droga], best.ntree, T))
a = rbind(a, cbind("tr. error", error_randomforest(train[, -13], train[, droga], 
                                                   train[, -13], train[, droga], 
                                                   best.ntree, T)))
a
```


